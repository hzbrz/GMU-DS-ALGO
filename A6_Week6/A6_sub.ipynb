{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3b730bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\"\"\"\n",
    "Hasan Zahid\n",
    "\n",
    "11/15/2021\n",
    "\n",
    "IT-309-001\n",
    "\n",
    "Input: Text file containing string data which indicate the transaction to be done and the data for \n",
    "the transaction on each line.\n",
    "\n",
    "Processing: Each line of the text will be appropriately hashed and inserted into the hash table after being compressed\n",
    "to fit the size of the table\n",
    "\n",
    "Output: Hash table containing data appropraite to each transaction read from the text file\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5c1e56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "HTcapacity = 99           # Allocate slots in the Hash Table - can be varied\n",
    "HT = [None]*HTcapacity    # 'HT' is the hash table data structure  \n",
    "multFactor = 137          # multiplication factor used by Hash function - can be varied\n",
    "print(len(HT))            # Verify HT capacity\n",
    "def loadfactor(itemcount, tableSize):    # function to calc load factor of the table\n",
    "    return itemcount/tableSize\n",
    "\n",
    "def cells_examined(load):\n",
    "    return .5*(1+(1/(1-load)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16370b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "I,Rizzo,Mike,1962,M,PhEd     I,Warden,Jackie,1998,F,Math\n"
     ]
    }
   ],
   "source": [
    "fname = 'IT309-A4-input.txt'  # Make this the name of your local file\n",
    "with open(f'{fname}') as f:\n",
    "    contents = f.readlines()\n",
    "\n",
    "a = []\n",
    "for x in contents:          # creating a list from txt without the any trailing chars like '\\n'\n",
    "    a.append(x.rstrip())\n",
    "    if x.rstrip() == '':\n",
    "        a.pop(-1)\n",
    "        break\n",
    "# print(a)   \n",
    "print(len(a))\n",
    "print(a[0], '   ', a[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb17b7f",
   "metadata": {},
   "source": [
    "#### This \"inlists\" 2d list created below will be used as main input into the hash function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74d6ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inlists = [x.split(',') for x in a]        # Create a list-of-lists for the input transactions\n",
    "# print(inlists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405bb422",
   "metadata": {},
   "source": [
    "#### The Hash function below generates the hashcode for each line and also generates the index for each code on the hashtable. This is done by compressing the large hashcode to fit into a sized list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0e67ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hash (inline, mFactor = 1123):\n",
    "    \"\"\"Hash function - takes an input line and returns the HT code. \"\"\"\n",
    "    s_tc = ''                # string to be converted\n",
    "    for line in inline[1:]:\n",
    "        s_tc = s_tc + str(line)     # portion of each string without the transaction code\n",
    "    # doing the polynomial generalized string encoing showed in class lectures\n",
    "    hashcode = 0\n",
    "    for i in range(len(s_tc)):\n",
    "        c = s_tc[i]\n",
    "#         print(f'char={c}, ASCII={ord(c)},  hashcode={(ord(c)*127**i)}')\n",
    "        hashcode += ord(c)*(127**i)    # prime-127 reduces num of collisions \n",
    "    return (hashcode)%HTcapacity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c542cf5",
   "metadata": {},
   "source": [
    "#### Below are the transactions being handled alongside the collisions that occur during insertions to the hash table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "713c94fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted: ['I', 'Rizzo', 'Mike', '1962', 'M', 'PhEd']\n",
      "Inserted: ['I', 'Womack', 'Mary', '1972', 'F', 'Math']\n",
      "Inserted: ['I', 'Smith', 'Marv', '1978', 'M', 'CS']\n",
      "Inserted: ['I', 'Miller', 'Samuel', '1974', 'M', 'HIST']\n",
      "Inserted: ['I', 'Kelvin', 'Katrina', '1982', 'F', 'ARTH']\n",
      "Inserted: ['I', 'Sherman', 'Maria', '1992', 'F', 'IST']\n",
      "Inserted: ['I', 'Ali', 'Hassan', '1996', 'M', 'MUSC']\n",
      "Inserted: ['I', 'Smith', 'Mary', '1999', 'F', 'ENGR']\n",
      "Inserted: ['I', 'Miller', 'Smuel', '1976', 'M', 'HIST']\n",
      "Inserted: ['I', 'Adams', 'Stuart', '2000', 'M', 'Food']\n",
      "Inserted: ['I', 'Lomack', 'Marv', '1971', 'M', 'Mgt']\n",
      "Inserted: ['I', 'Strasburg', 'Stephen', '1988', 'M', 'PhEd']\n",
      "Inserted: ['I', 'Thompson', 'Creek', '2000', 'F', 'ACCT']\n",
      "Inserted: ['I', 'Bryson', 'William', '1997', 'M', 'ENGL']\n",
      "Inserted: ['I', 'Eaton', 'Adam', '1989', 'M', 'Math']\n",
      "Inserted: ['I', 'Jones', 'Johann', '1996', 'M', 'ENGR']\n",
      "Inserted: ['I', 'Kevin', 'Katherine', '1997', 'F', 'HIST']\n",
      "Inserted: ['I', 'Rizzo', 'Frank', '1961', 'M', 'PSci']\n",
      "Inserted: ['I', 'Doan', 'Quang', '1969', 'M', 'Math']\n",
      "Inserted: ['I', 'Ebert', 'Linda', '1991', 'F', 'CHHS']\n",
      "Inserted: ['I', 'Stanford', ' Lleland', '1965', 'M', 'BUS']\n",
      "Inserted: ['I', 'Ford', 'Henry', '1972', 'M', 'MGT']\n",
      "Inserted: ['I', 'Bryson', 'Wilson', '1998', 'M', 'ENGR']\n",
      "Inserted: ['I', 'Smith', 'Mary', '1999', 'F', 'ENGR']\n",
      "Inserted: ['I', 'Garcia', 'Manuel', '1998', 'M', 'CS']\n",
      "Inserted: ['I', 'Vicente', 'Alberto', '1979', 'M', 'Ling']\n",
      "Inserted: ['I', 'Principato', 'Geraldo', '1994', 'M', 'ENGL']\n",
      "Inserted: ['I', 'Principle', 'Victoria', '1982', 'F', 'THEA']\n",
      "Inserted: ['I', 'Shurman', 'Maria', '1992', 'F', 'HUM']\n",
      "Inserted: ['I', 'Kelvin', 'Katrina', '1982', 'F', 'ARTH']\n",
      "['R', 'Rizzo', 'Frank', '1961', 'PSci'] \t ['I', 'Ali', 'Hassan', '1996', 'M', 'MUSC'] \t 95\n",
      "['R', 'Smith', 'Marv', '1978', 'M', 'CS'] \t ['I', 'Smith', 'Marv', '1978', 'M', 'CS'] \t 89\n",
      "Removed: ['R', 'Smith', 'Marv', '1978', 'M', 'CS']\n",
      "Inserted: ['I', 'Ford', 'Edsel', '1940', 'M', 'MGT']\n",
      "Searching: Found\n",
      "Searching: Not found\n",
      "Inserted: ['I', 'Korbut', 'Olga', '1960', 'F', 'DANC']\n",
      "Inserted: ['I', 'Khorkina', 'Svetlana', '1978', 'F', 'ENGR']\n",
      "Inserted: ['I', 'Martinez', 'David', '1971', 'M', 'PhEd']\n",
      "Inserted: ['I', 'Snyder', 'Daniel', '1974', 'M', 'BUS']\n",
      "Inserted: ['I', 'Angelos', 'Peter', '1940', 'M', 'MGT']\n",
      "Inserted: ['I', 'Jones', 'Johanna', '1997', 'F', 'ENGL']\n",
      "Inserted: ['I', 'MacGillacudy', 'Lucille', '1954', 'F', 'THEA']\n",
      "Inserted: ['I', 'Lockhorn', 'Leonard', '1992', 'M', 'CHEM']\n",
      "Inserted: ['I', 'Gomez', 'Maria', '1998', 'F', 'Phil']\n",
      "Inserted: ['I', 'Rydell', 'Robert', '1969', 'M', 'MUSC']\n",
      "Inserted: ['I', 'Howard', 'Irene', '1989', 'F', 'ENGR']\n",
      "Inserted: ['I', 'Leiby', 'Nancy', '1998', 'F', 'Math']\n",
      "Inserted: ['I', 'Gauss', 'Karl', '1940', 'M', 'Phil']\n",
      "Inserted: ['I', 'Ramanajan', 'Sanji', '1976', 'M', 'Math']\n",
      "Inserted: ['I', 'Disaeli', 'Benjamin', '1825', 'M', 'PSci']\n",
      "['R', 'Ford', 'Henry', '1972', 'M', 'MGT'] \t ['I', 'Ford', 'Henry', '1972', 'M', 'MGT'] \t 74\n",
      "Removed: ['R', 'Ford', 'Henry', '1972', 'M', 'MGT']\n",
      "Inserted: ['I', 'Lord', 'Jonathon', '1941', 'M', 'MUSC']\n",
      "Searching: Found\n",
      "Searching: Not found\n",
      "Inserted: ['I', 'Kaat', 'James', '1959', 'M', 'PhEd']\n",
      "Inserted: ['I', 'Desdion', 'Gerard', '1972', 'M', 'FREN']\n",
      "Inserted: ['I', 'Warren', 'Esmerelda', '1976', 'F', 'CS']\n",
      "Inserted: ['I', 'Warden', 'Jack', '1998', 'M', 'Math']\n",
      "Inserted: ['I', 'SmithSmith', 'Smithy', '1982', 'M', 'HIST']\n",
      "Inserted: ['I', 'Sagan', 'Carl', '1940', 'M', 'ASTR']\n",
      "Inserted: ['I', 'Druyan', 'Ann', '1959', 'CHEM']\n",
      "['R', 'Gauss', 'Karl', '1940', 'M', 'Phil'] \t ['I', 'Gauss', 'Karl', '1940', 'M', 'Phil'] \t 86\n",
      "Removed: ['R', 'Gauss', 'Karl', '1940', 'M', 'Phil']\n",
      "Inserted: ['I', 'Zebub', 'Be-el', '1970', 'M', 'Rel']\n",
      "Inserted: ['I', 'Jaegar', 'Karina', '1997', 'F', 'CHEM']\n",
      "Searching: Not found\n",
      "Inserted: ['I', 'Grant', 'James', '1965', 'M', 'ENGR']\n",
      "Inserted: ['I', 'Crabbe', 'Henry', '1979', 'M', 'Food']\n",
      "['R', 'Gladstone', 'Jonathon', '1930', 'M', 'PSci'] \t ['I', 'Korbut', 'Olga', '1960', 'F', 'DANC'] \t 89\n",
      "Inserted: ['I', 'Chamberlain', 'Neville', '1890', 'M', 'Phys']\n",
      "Inserted: ['I', 'Hopkins', 'Susan', '1954', 'F', 'JOUR']\n",
      "Inserted: ['I', 'Smith', 'Mary', '1999', 'F', 'ENGR']\n",
      "Inserted: ['I', 'Vicente', 'Alfredo', '1979', 'M', 'Ling']\n",
      "Inserted: ['I', 'Hardcastle', 'Morvena', '1987', 'F', 'CS']\n",
      "['R', 'Smith', 'Mary', '1999', 'F', 'ENGR'] \t ['I', 'Smith', 'Mary', '1999', 'F', 'ENGR'] \t 67\n",
      "Removed: ['R', 'Smith', 'Mary', '1999', 'F', 'ENGR']\n",
      "Inserted: ['I', 'Smits', 'Jimmy', '1998', 'M', 'THEAI', '']\n",
      "Searching: Not found\n",
      "Inserted: ['I', 'Sox', 'Bobby', '1992', 'F', 'PhEd']\n",
      "Inserted: ['I', 'Ortiz', 'David', '1980', 'M', 'Phys']\n",
      "Searching: Not found\n",
      "Searching: Not found\n",
      "Inserted: ['I', 'Rodriguez', 'Hector', '1987', 'M', 'ENGR']\n",
      "Inserted: ['I', 'Li', 'Stephanie', '1998', 'F', 'ARTH']\n",
      "Inserted: ['I', 'Das', 'Petra', '1999', 'F', 'ENGR']\n",
      "['R', 'Druyan', 'Ann', '1959', 'CHEM'] \t ['I', 'Druyan', 'Ann', '1959', 'CHEM'] \t 0\n",
      "Removed: ['R', 'Druyan', 'Ann', '1959', 'CHEM']\n",
      "Inserted: ['I', 'Warden', 'Jackie', '1998', 'F', 'Math']\n"
     ]
    }
   ],
   "source": [
    "HT = [None] * HTcapacity\n",
    "collisions = 0\n",
    "entry = 0\n",
    "deleted = 0\n",
    "for line in inlists:\n",
    "    if line[0] == 'I':    # handling Insert transaction        \n",
    "        hcode = Hash(line, mFactor=multFactor)    # genrating the hashcode for insert\n",
    "        \n",
    "        if HT[hcode] == None or HT[hcode] == 'deleted':    # equaling None means empty slot to insert into\n",
    "            HT[hcode] = line\n",
    "            entry+=1\n",
    "        else:      # collision occured: quadratic probing is used to handle collisions by finding the next empty slot\n",
    "            collisions += 1\n",
    "            for i in range(HTcapacity):\n",
    "                qp_hcode = (hcode+i*i)%HTcapacity    # new hash limited by the table size\n",
    "                \n",
    "                # if the quadratic place is equal to None or hash has been deleted at that index \n",
    "                # we can insert without collision\n",
    "                if HT[qp_hcode] is None or HT[qp_hcode] == 'deleted':        \n",
    "                    HT[qp_hcode] = line\n",
    "                    break\n",
    "        print(f'Inserted: {line}')\n",
    "    elif line[0] == 'R':    # handling Remove transaction\n",
    "        hcode = Hash(line, mFactor=multFactor)\n",
    "        print(f'{line} \\t {HT[hcode]} \\t {hcode}')\n",
    "        if HT[hcode] != None:\n",
    "            if HT[hcode][1:] == line[1:]:    # also checking if the element is same, in case hashcode = collission slot\n",
    "                HT[hcode] = 'deleted'\n",
    "                print(f'Removed: {line}')\n",
    "                deleted += 1\n",
    "    else:                   # handling Find transaction\n",
    "        hcode = Hash(line, mFactor=multFactor)\n",
    "        if HT[hcode] == None:\n",
    "            print('Searching: Not found')\n",
    "        else:\n",
    "            if HT[hcode][1:] == line[1:]:\n",
    "                print('Searching: Found')\n",
    "            else:\n",
    "                print('Searching: Not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93bc1393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index # 0  =  deleted\n",
      "index # 1  =  ['I', 'Hopkins', 'Susan', '1954', 'F', 'JOUR']\n",
      "index # 2  =  ['I', 'Chamberlain', 'Neville', '1890', 'M', 'Phys']\n",
      "index # 3  =  ['I', 'Sherman', 'Maria', '1992', 'F', 'IST']\n",
      "index # 4  =  ['I', 'Shurman', 'Maria', '1992', 'F', 'HUM']\n",
      "index # 5  =  ['I', 'SmithSmith', 'Smithy', '1982', 'M', 'HIST']\n",
      "index # 6  =  ['I', 'Principato', 'Geraldo', '1994', 'M', 'ENGL']\n",
      "index # 7  =  ['I', 'Warden', 'Jackie', '1998', 'F', 'Math']\n",
      "index # 8  =  ['I', 'Kelvin', 'Katrina', '1982', 'F', 'ARTH']\n",
      "index # 9  =  ['I', 'Kelvin', 'Katrina', '1982', 'F', 'ARTH']\n",
      "index # 10  =  ['I', 'Grant', 'James', '1965', 'M', 'ENGR']\n",
      "index # 11  =  ['I', 'Vicente', 'Alfredo', '1979', 'M', 'Ling']\n",
      "index # 12  =  ['I', 'Angelos', 'Peter', '1940', 'M', 'MGT']\n",
      "index # 13  =  ['I', 'Desdion', 'Gerard', '1972', 'M', 'FREN']\n",
      "index # 14  =  ['I', 'Ebert', 'Linda', '1991', 'F', 'CHHS']\n",
      "index # 15  =  None\n",
      "index # 16  =  None\n",
      "index # 17  =  ['I', 'Principle', 'Victoria', '1982', 'F', 'THEA']\n",
      "index # 18  =  None\n",
      "index # 19  =  ['I', 'Das', 'Petra', '1999', 'F', 'ENGR']\n",
      "index # 20  =  ['I', 'Warden', 'Jack', '1998', 'M', 'Math']\n",
      "index # 21  =  ['I', 'Rydell', 'Robert', '1969', 'M', 'MUSC']\n",
      "index # 22  =  ['I', 'Ramanajan', 'Sanji', '1976', 'M', 'Math']\n",
      "index # 23  =  None\n",
      "index # 24  =  ['I', 'Kaat', 'James', '1959', 'M', 'PhEd']\n",
      "index # 25  =  ['I', 'Gomez', 'Maria', '1998', 'F', 'Phil']\n",
      "index # 26  =  None\n",
      "index # 27  =  ['I', 'Howard', 'Irene', '1989', 'F', 'ENGR']\n",
      "index # 28  =  ['I', 'Garcia', 'Manuel', '1998', 'M', 'CS']\n",
      "index # 29  =  ['I', 'Lockhorn', 'Leonard', '1992', 'M', 'CHEM']\n",
      "index # 30  =  ['I', 'Ortiz', 'David', '1980', 'M', 'Phys']\n",
      "index # 31  =  None\n",
      "index # 32  =  None\n",
      "index # 33  =  ['I', 'Rizzo', 'Mike', '1962', 'M', 'PhEd']\n",
      "index # 34  =  None\n",
      "index # 35  =  None\n",
      "index # 36  =  None\n",
      "index # 37  =  None\n",
      "index # 38  =  ['I', 'Crabbe', 'Henry', '1979', 'M', 'Food']\n",
      "index # 39  =  ['I', 'Miller', 'Samuel', '1974', 'M', 'HIST']\n",
      "index # 40  =  ['I', 'Smits', 'Jimmy', '1998', 'M', 'THEAI', '']\n",
      "index # 41  =  None\n",
      "index # 42  =  None\n",
      "index # 43  =  ['I', 'Eaton', 'Adam', '1989', 'M', 'Math']\n",
      "index # 44  =  ['I', 'Zebub', 'Be-el', '1970', 'M', 'Rel']\n",
      "index # 45  =  None\n",
      "index # 46  =  ['I', 'Warren', 'Esmerelda', '1976', 'F', 'CS']\n",
      "index # 47  =  None\n",
      "index # 48  =  ['I', 'Thompson', 'Creek', '2000', 'F', 'ACCT']\n",
      "index # 49  =  ['I', 'Sox', 'Bobby', '1992', 'F', 'PhEd']\n",
      "index # 50  =  ['I', 'Vicente', 'Alberto', '1979', 'M', 'Ling']\n",
      "index # 51  =  None\n",
      "index # 52  =  None\n",
      "index # 53  =  ['I', 'Khorkina', 'Svetlana', '1978', 'F', 'ENGR']\n",
      "index # 54  =  None\n",
      "index # 55  =  ['I', 'Bryson', 'William', '1997', 'M', 'ENGL']\n",
      "index # 56  =  ['I', 'Womack', 'Mary', '1972', 'F', 'Math']\n",
      "index # 57  =  ['I', 'Lord', 'Jonathon', '1941', 'M', 'MUSC']\n",
      "index # 58  =  None\n",
      "index # 59  =  ['I', 'Rizzo', 'Frank', '1961', 'M', 'PSci']\n",
      "index # 60  =  ['I', 'Bryson', 'Wilson', '1998', 'M', 'ENGR']\n",
      "index # 61  =  ['I', 'Sagan', 'Carl', '1940', 'M', 'ASTR']\n",
      "index # 62  =  None\n",
      "index # 63  =  ['I', 'MacGillacudy', 'Lucille', '1954', 'F', 'THEA']\n",
      "index # 64  =  ['I', 'Jones', 'Johann', '1996', 'M', 'ENGR']\n",
      "index # 65  =  None\n",
      "index # 66  =  None\n",
      "index # 67  =  deleted\n",
      "index # 68  =  ['I', 'Smith', 'Mary', '1999', 'F', 'ENGR']\n",
      "index # 69  =  ['I', 'Leiby', 'Nancy', '1998', 'F', 'Math']\n",
      "index # 70  =  None\n",
      "index # 71  =  ['I', 'Smith', 'Mary', '1999', 'F', 'ENGR']\n",
      "index # 72  =  None\n",
      "index # 73  =  ['I', 'Stanford', ' Lleland', '1965', 'M', 'BUS']\n",
      "index # 74  =  ['I', 'Rodriguez', 'Hector', '1987', 'M', 'ENGR']\n",
      "index # 75  =  None\n",
      "index # 76  =  ['I', 'Disaeli', 'Benjamin', '1825', 'M', 'PSci']\n",
      "index # 77  =  ['I', 'Snyder', 'Daniel', '1974', 'M', 'BUS']\n",
      "index # 78  =  None\n",
      "index # 79  =  ['I', 'Miller', 'Smuel', '1976', 'M', 'HIST']\n",
      "index # 80  =  ['I', 'Ford', 'Edsel', '1940', 'M', 'MGT']\n",
      "index # 81  =  None\n",
      "index # 82  =  ['I', 'Adams', 'Stuart', '2000', 'M', 'Food']\n",
      "index # 83  =  ['I', 'Strasburg', 'Stephen', '1988', 'M', 'PhEd']\n",
      "index # 84  =  None\n",
      "index # 85  =  None\n",
      "index # 86  =  deleted\n",
      "index # 87  =  ['I', 'Hardcastle', 'Morvena', '1987', 'F', 'CS']\n",
      "index # 88  =  ['I', 'Doan', 'Quang', '1969', 'M', 'Math']\n",
      "index # 89  =  ['I', 'Korbut', 'Olga', '1960', 'F', 'DANC']\n",
      "index # 90  =  None\n",
      "index # 91  =  ['I', 'Li', 'Stephanie', '1998', 'F', 'ARTH']\n",
      "index # 92  =  ['I', 'Jaegar', 'Karina', '1997', 'F', 'CHEM']\n",
      "index # 93  =  None\n",
      "index # 94  =  ['I', 'Lomack', 'Marv', '1971', 'M', 'Mgt']\n",
      "index # 95  =  ['I', 'Ali', 'Hassan', '1996', 'M', 'MUSC']\n",
      "index # 96  =  ['I', 'Jones', 'Johanna', '1997', 'F', 'ENGL']\n",
      "index # 97  =  ['I', 'Kevin', 'Katherine', '1997', 'F', 'HIST']\n",
      "index # 98  =  ['I', 'Martinez', 'David', '1971', 'M', 'PhEd']\n"
     ]
    }
   ],
   "source": [
    "for n in range(0, len(HT)):\n",
    "    print('index #', n, ' = ', HT[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd09d90d",
   "metadata": {},
   "source": [
    "#### Experimentation and Analysis Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27460da",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A little bit of processing is done to clean the line of any trailing characters or commas beforehand. The Hash function above is implemented using two parts, one is to generate a hash code from each line of the text file joined without the commas and transaction codes ('I', 'R', 'F') and secondly the hashcode is compressed to fit the hash table. The purpose of the hashcode is to take the processed string and turn it into some integer which can then be mapped to some index inside the hash table. The hascode is computed using the polynomial string encoding formula given in the lecutres, which is the sum of each character in the string turned into its ASCII equivalent and then multiplied by some prime number raised to the index of the character in the string. For example lets say we read the first line from the text file: 'I,Rizzo,Mike,1962,M,PhEd\\n' after a little bit of processing, the input to the hash function becomes a list-of-list like: \\['I', 'Rizzo', 'Mike', '1962', 'M', 'PhEd'\\]. From there only the part <b>without</b> the transaction code 'I' is joined into one string without whitespaces: RizzoMike1962MPhEd, this is what the string encoding formula is applied on to get a hashcode — a very large number. To demonstrate, the first character \"R\" of the string \"RizzoMike1962MPhEd\" encoded is just 82 but after every character is encoded the generated hashcode is an absurdly large number—58165204085625034858110394280850444700.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;So, now comes the second part which answers the question of how to fit this large number into a table(list) of certain size, this is done by compressing the large number using the modulo operator getting a remainder — a number between 0 and the hash table's size-1. This is the index into which we can map the hashcode. As a sidenote this hashing algorithm doesn't use the multFactor, just a normal division compression formula is used. Now that the hashing function is understood, a common problem that occurs during this process is when two different inputs map to the same hash causing collisions. Collisions (in this case) are handled using the open addressing strategy of quadratic probing. This probing technique finds open slots in the table by looping over the table in quadractic fashion. The quadratic probing method — as any other probing method — also produces clustering. Clustering is when large number of inputs are grouped together in consecutive slots in the hash table. This leads to the probing method having to examine more slots to find an empty slot leading to higher run time. \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Clustering is dependant on the load factor which is dependant on the table size. Keeping the load factor below 0.5 is a method to reduce clustering which can be done by increasing the table size in this case. Given the table size of 99 and the inputs as text file from blackboard, the current hash function encounters 17 collisions out of 70 entries and on average about 6 slots were examined before a collision was resolved. Which is pretty bad due to how quickly the number of slots examined rises with an increasing load factor. The load factor at 20 entries was about 0.2 and at 50 entries is 0.5 and by the end the load factor is 0.7 indicating the hash table is 70% filled. \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Now some experiments can be done to see how it affects the number of collisions, the average number of cells examined/clustering, load factor relative to the table size and number of open slots. First lets establish the base numbers using the original hashing function/table size: num. of collisions: 17, num. of open slots: 31, load factor: 0.7, average num of slots examined in probing: 6.33. So, lets say we change the input string to just a subset of it, meaning running hashing on just \"RizzoMike\" instead of \"RizzoMike1962MPhEd\" increases the number of collisions to 23 but all other factors stay the same. Reverting back to using the whole string instead of the subset, now I change how the hashcode is calculated by taking out the arbitrary multiplier from this: hashcode += ord(c)\\*(127\\*\\*i) to hashcode += ord(c)\\*\\*i. This causes the number of collisions to go up to 29 and reduces the number of open slots by 1 to 30. Lastly, I revert back the hashcode changes and only change the table size (HTcapacity) which will have somewhat predictable outcomes for the hashtable and its properties. Decreasing the table size to some small number like 59 increases the number of collisions to 43, increases the load factor to about 1.2 which in turn increases the average number of slots examined while probing to about 15 and obviously there are no open slots remaining. Conversely, increasing the table size to some big number like 211 reduces the number of collisions to 15, minimizes the load factor to about 0.3 which means there is less clusterning and the average number of slots examined reduces to about 1.6 during probing, there are also now 141 open slots for insertion. This shows that hashing is very effective if we are willing to sacrifice the memory space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9642f65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of entries: 53\n",
      "# of collisions: 17\n",
      "# of open slots: 31\n",
      "# of deletions: 5\n",
      "total items: 70\n",
      "Load factor: 0.7070707070707071\n",
      "average # of cells examined: 6.326991676575505\n"
     ]
    }
   ],
   "source": [
    "print(f'# of entries: {entry}')\n",
    "print(f'# of collisions: {collisions}')\n",
    "open_slots = [o for o in HT if o is None]\n",
    "print(f'# of open slots: {len(open_slots)}')\n",
    "print(f'# of deletions: {deleted}')\n",
    "items = entry+collisions\n",
    "print(f'total items: {items}')\n",
    "lf = loadfactor(70, HTcapacity)\n",
    "print(f'Load factor: {lf}')\n",
    "print(f'average # of cells examined: {cells_examined(lf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792f971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
